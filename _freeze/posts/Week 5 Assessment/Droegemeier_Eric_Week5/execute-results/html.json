{
  "hash": "6ebce721eb7d53b54c7fb84d7d5579f7",
  "result": {
    "markdown": "---\ntitle: \"ADTA 5410 by Bulut, Week 5 Lab\"\nauthor: \"Eric Droegemeier\"\nformat: html\neditor: visual\n---\n\n\n## General Instructions\n\n1.  You have the option to establish a new folder for this lab assignment and place both this Quarto document and the supplied dataset within it.\n\n2.  The initial code snippet installs specific R packages that could prove valuable in addressing certain questions.\n\n3.  Unless otherwise specified, you have the freedom to select any R package you prefer to address the questions. You are not constrained to utilizing the packages listed in this Quarto template.\n\n4.  Ensure that you include the code responsible for generating each answer, and verify that both your code and its output are visible in your knitted HTML document. You can achieve this by setting **`echo=TRUE`** to print your code chunk in the knitted HTML code.\n\n5.  Once you've completed your work, knit your Quarto document into an HTML document and save it within the folder you established in step 1.\n\n6.  Please submit your assignment by uploading both the knitted HTML document and the QMD file to the specified course portal on Canvas prior to the designated due date and time\n\n7.  Ensure your Quarto Document is saved with the following naming convention: \"**LastName_FirstName_Week5.qmd**\" (i.e. Doe_Jane_Week5.qmd). Students will lose 2 points for improper file naming.\n\n8.  Please place your code for each task within the specified code section.\n\n9.  Ensure that all non-code written responses are placed within the corresponding Task section where the question content is located.\n\n10. You are allowed to seek assistance from ChatGPT exclusively for assistance in writing your code. However, please be cautious as ChatGPT may occasionally provide inaccurate information when it comes to scripting in specific programming languages.\n\n11. Verbal responses must be articulated in your own words. You cannot use ChatGPT for generating or providing verbal responses. All verbal responses should originate from your own understanding and expression.\n\n\n::: {.cell}\n\n:::\n\n\n## Week 5 Assignment\n\n## Business Problem\n\nFor this week's homework, we'll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we'll be using is a randomly selected subset of the original dataset.\n\n**Attributes:**\n\n-   **Predictors**\n\n    -   **fage**: father's age in years.\n\n    -   **mage**: mother's age in years.\n\n    -   **mature**: maturity status of mother.\n\n    -   **weeks**: length of pregnancy in weeks.\n\n    -   **premie**: whether the birth was classified as premature (premie) or full-term.\n\n    -   **visits**: number of hospital visits during pregnancy.\n\n    -   **marital**: whether mother is married or not married at birth.\n\n    -   **gained**: weight gained by mother during pregnancy in pounds.\n\n    -   **gender**: gender of the baby, female or male.\n\n    -   **habit**: status of the mother as a nonsmoker or a smoker.\n\n    -   **whitemom**: whether mother is white or not white.\n\n**Outcome Variable:**\n\n-   **weight**: weight of the baby at birth in pounds. (Regression problem)\n\n#### Do not change anything in this r chunk. Just run the code chunk and move to the next one\n\n\n::: {.cell}\n\n:::\n\n\n## Task 1: Data Preparation\n\n::: {.callout-important appearance=\"simple\"}\n## Task 1\n\n1.  **Data Structure Check**:\n\n    -   Examine the variable descriptions and the overall structure of the dataset in **`mydata`**.\n\n    -   Ensure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\n2.  **Handling Missing Values**:\n\n    -   Identify and replace missing values in your dataset.\n\n        -   For numeric variables, fill missing values with the median of that variable.\n\n        -   For categorical variables, use the most frequent category (mode) to replace missing values.\n\n3.  **Correlation Analysis and Visualization**:\n\n    -   Determine the variable that has the highest correlation (in absolute value) with your chosen target variable.\n\n    -   Create a scatter plot to visually represent the relationship between these two variables.\n\n    -   Provide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\n\n    -   **Insert your written response in here:**\n:::\n\n## Your code for Task 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 1 in this code chunk\n\n# Display the structure of the dataset\nstr(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n```\n:::\n\n```{.r .cell-code}\n# Convert character variables to factors\nmydata$mature <- as.factor(mydata$mature)\nmydata$premie <- as.factor(mydata$premie)\nmydata$marital <- as.factor(mydata$marital)\nmydata$gender <- as.factor(mydata$gender)\nmydata$habit <- as.factor(mydata$habit)\nmydata$whitemom <- as.factor(mydata$whitemom)\n\n# Identify missing values\nmissing_values <- sapply(mydata, function(x) sum(is.na(x)))\n\n# Display missing values\nprint(missing_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    fage     mage   mature    weeks   premie   visits  marital   gained \n     170        0        0        1        1        8        0       26 \n  weight   gender    habit whitemom \n       0        0        0        2 \n```\n:::\n\n```{.r .cell-code}\n# Replace missing values with median for numeric variables and mode for factor variables\n\nmydata$fage[is.na(mydata$fage)] <- median(mydata$fage, na.rm = TRUE)\n\nmydata$mage[is.na(mydata$mage)] <- median(mydata$mage, na.rm = TRUE)\n\nmode_mature <- levels(mydata$mature)[which.max(table(mydata$mature))]\nmydata$mature[is.na(mydata$mature)] <- mode_mature\n\nmydata$weeks[is.na(mydata$weeks)] <- median(mydata$weeks, na.rm = TRUE)\n\nmode_premie <- levels(mydata$premie)[which.max(table(mydata$premie))]\nmydata$premie[is.na(mydata$premie)] <- mode_premie\n\nmydata$visits[is.na(mydata$visits)] <- median(mydata$visits, na.rm = TRUE)\n\nmode_marital <- levels(mydata$marital)[which.max(table(mydata$marital))]\nmydata$marital[is.na(mydata$marital)] <- mode_marital\n\nmydata$gained[is.na(mydata$gained)] <- median(mydata$gained, na.rm = TRUE)\n\nmydata$weight[is.na(mydata$weight)] <- median(mydata$weight, na.rm = TRUE)\n\nmode_gender <- levels(mydata$gender)[which.max(table(mydata$gender))]\nmydata$gender[is.na(mydata$gender)] <- mode_gender\n\nmode_habit <- levels(mydata$habit)[which.max(table(mydata$habit))]\nmydata$habit[is.na(mydata$habit)] <- mode_habit\n\nmode_whitemom <- levels(mydata$whitemom)[which.max(table(mydata$whitemom))]\nmydata$whitemom[is.na(mydata$whitemom)] <- mode_whitemom\n\n# Group variables together for ease of coding\nnumeric_variables <- sapply(mydata, is.numeric)\ncategorical_variables <- sapply(mydata, is.factor)\n\n# Verify that missing values are handled\nmissing_values_after <- sapply(mydata, function(x) sum(is.na(x)))\nprint(missing_values_after)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    fage     mage   mature    weeks   premie   visits  marital   gained \n       0        0        0        0        0        0        0        0 \n  weight   gender    habit whitemom \n       0        0        0        0 \n```\n:::\n\n```{.r .cell-code}\n# Correlation analysis\ncorrelation_matrix <- cor(mydata[, numeric_variables])\ncor_target <- correlation_matrix[,'weight']\n\n# Print correlation matrix\nprint(\"Correlation Matrix:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Correlation Matrix:\"\n```\n:::\n\n```{.r .cell-code}\nprint(correlation_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              fage        mage       weeks     visits      gained     weight\nfage    1.00000000  0.71097608 -0.01354686 0.07311167 -0.03733005 0.06477083\nmage    0.71097608  1.00000000 -0.03189211 0.16008945 -0.05953958 0.06057405\nweeks  -0.01354686 -0.03189211  1.00000000 0.17137999  0.08938433 0.67009588\nvisits  0.07311167  0.16008945  0.17137999 1.00000000  0.05847809 0.13296305\ngained -0.03733005 -0.05953958  0.08938433 0.05847809  1.00000000 0.15089295\nweight  0.06477083  0.06057405  0.67009588 0.13296305  0.15089295 1.00000000\n```\n:::\n\n```{.r .cell-code}\n# from the correlation matrix, the strongest correlation to weight is weight, obviously. I have also created a second scatter plot that shows the 2nd strongest correlation between weight and weeks. This makes sense as babies that are born prematurely will weigh less than babies born on time, and as babies that are born closer to the expected due date will have their weights vary more. The correlation between weeks and weight is moderately positive. - EJD\n\n# Identify the variable with the highest correlation\nhighest_correlation <- names(which.max(abs(cor_target)))\n\n# Scatter plot\nplot(mydata$weight, mydata[, highest_correlation], \n     xlab = 'Weight of the Baby at Birth (lbs)', \n     ylab = paste('Correlated Variable:', highest_correlation),\n     main = 'Scatter Plot: Baby Weight vs. Highest Correlated Variable')\nabline(lm(mydata[, highest_correlation] ~ mydata$weight), col = 'red')\n```\n\n::: {.cell-output-display}\n![](Droegemeier_Eric_Week5_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create scatter plot\nggplot(mydata, aes(x = weeks, y = weight)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Weeks vs. Weight\",\n       x = \"Weeks\",\n       y = \"Weight\")\n```\n\n::: {.cell-output-display}\n![](Droegemeier_Eric_Week5_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n## Task 2: Data Splitting\n\n------------------------------------------------------------------------\n\n::: {.callout-important appearance=\"simple\"}\n## Task 2\n\n-   Prior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you'll need to use the **`initial_split`** function from the **`rsample`** package in R to partition the data. Please ensure to use **`set.seed(123456)`** for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using `strata=\"weight\"`.\n\n-   Name your training set **`train_data`** and your test set **`test_data`**. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance.\n:::\n\n## Your code for Task 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\ndata_split <- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Create training and test sets\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n```\n:::\n\n\n## Task 3:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 3\n\n-   In this task, you will be using the **`train_data`** dataset to run a linear regression that takes `weight` as the dependent variable and all the other columns as the predictor.\n\n    -   You will use the **`lm()`** function to estimate your linear model and name it as **`linearmodel`**.\n\n    -   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`linearmodel`**.\n\n    -   Store the resulting predictions in a new object called **`predicted_weights_ols`**.\n\n    -   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted `weight` values with the actual `weight` values. Store the resulting value in an object called **`MSPE_linear`**.\n\n-   **Need Written Response:** Print the value of **`MSPE_linear`** to the console using the **`print()`** function\n:::\n\n## Your code for Task 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 3  in this code chunk\n\n# Run linear regression\nlinearmodel <- lm(weight ~ ., data = train_data)\n\n# Predict weight in the test_data dataset\npredicted_weights_ols <- predict(linearmodel, newdata = test_data)\n\n# Calculate mean squared prediction error (MSPE)\nMSPE_linear <- mean((predicted_weights_ols - test_data$weight)^2)\n\n# Print the value of MSPE_linear to the console\nprint(MSPE_linear)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.133044\n```\n:::\n:::\n\n\n## Task 4:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 4\n\n-   Use the `gam` function in the **`mgcv`** package to complete the same task. In other words, fit a Generalized additive model (GAM) on the `train_data` using the **`gam()`** function. Use the **`s()`** function for each **suitable** predictor. Save your R object as `gam_model.` If the `gam` output indicates that a variable should be added linearly to the model, then make the necessary changes in `gam_model` and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = \"REML\".\n-   Print out smoothing parameter from `gam_model.`\n-   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`gam_model`**. Store the resulting predictions in a new object called **`predicted_weights_gam`**.\n-   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted 'weight' values with the actual `weight` values. Store the resulting value in an object called **`MSPE_gam`**.\n\nPrint the value of **`MSPE_gam`** to the console using the **`print()`** function.\n:::\n\n## Your code for Task 4\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 4 in this code chunk\n\n# Fit a Generalized Additive Model (GAM) with reduced degrees of freedom\ngam_model <- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + s(gained) + marital + habit + whitemom + premie + gender, data = train_data, method = \"REML\")\n\n# Trim the GAM model to smooth the correct degrees of freedom\n\ngam_model_rev <- gam(weight ~ fage + mage + s(weeks) + s(visits) + gained + marital + habit + whitemom + premie + gender, data = train_data, method = \"REML\")\n\n\n# Print smoothing parameters\nsummary(gam_model)$s.table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               edf   Ref.df            F    p-value\ns(fage)   1.000221 1.000440  2.379022407 0.12342263\ns(mage)   1.000254 1.000508  0.001164886 0.97641943\ns(weeks)  4.692439 5.757398 40.915117144 0.00000000\ns(visits) 4.331207 5.333348  2.695964501 0.01788397\ns(gained) 1.000022 1.000045  3.810738979 0.05133240\n```\n:::\n\n```{.r .cell-code}\n# Predict weight in the test_data dataset using gam_model\npredicted_weights_gam <- predict(gam_model, newdata = test_data)\n\n# Calculate mean squared prediction error (MSPE) for the GAM model\nMSPE_gam <- mean((predicted_weights_gam - test_data$weight)^2)\n\n# Print the value of MSPE_gam to the console\nprint(MSPE_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.054482\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## TASK 5:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 5\n\n-   Evaluate the effectiveness of the linear regression model (**`linearmodel`**) and the generalized additive model (**`gam_model`**) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values **`MSPE_linear`** and **`MSPE_gam`**, which were derived in previous tasks, to assess which model more accurately predicts the 'weight' variable in the **`test_data`** dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.\n-   **Insert your written response in here:**\n:::\n\n## Your code for Task 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 5 in this code chunk\n\n# Compare MSPE for linear regression and GAM models\ncat(\"Mean Squared Prediction Error (MSPE) for Linear Regression Model:\", round(MSPE_linear, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Prediction Error (MSPE) for Linear Regression Model: 1.133 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Mean Squared Prediction Error (MSPE) for Generalized Additive Model (GAM):\", round(MSPE_gam, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Prediction Error (MSPE) for Generalized Additive Model (GAM): 1.0545 \n```\n:::\n\n```{.r .cell-code}\n# Evaluate model performance\nif (MSPE_linear < MSPE_gam) {\n  cat(\"Linear Regression Model has superior predictive performance for 'weight'.\\n\")\n} else if (MSPE_gam < MSPE_linear) {\n  cat(\"Generalized Additive Model (GAM) has superior predictive performance for 'weight'.\\n\")\n} else {\n  cat(\"Both models have similar predictive performance for 'weight'.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized Additive Model (GAM) has superior predictive performance for 'weight'.\n```\n:::\n\n```{.r .cell-code}\n# The GAM model performs better at predicting the target variable due to it having a lower MSPE as shown in the code block. - EJD\n```\n:::\n",
    "supporting": [
      "Droegemeier_Eric_Week5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}