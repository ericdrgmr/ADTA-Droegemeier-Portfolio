---
title: "ADTA 5410 by Bulut, Week 5 Lab"
author: "Eric Droegemeier"
format: html
editor: visual
---

## General Instructions

1.  You have the option to establish a new folder for this lab assignment and place both this Quarto document and the supplied dataset within it.

2.  The initial code snippet installs specific R packages that could prove valuable in addressing certain questions.

3.  Unless otherwise specified, you have the freedom to select any R package you prefer to address the questions. You are not constrained to utilizing the packages listed in this Quarto template.

4.  Ensure that you include the code responsible for generating each answer, and verify that both your code and its output are visible in your knitted HTML document. You can achieve this by setting **`echo=TRUE`** to print your code chunk in the knitted HTML code.

5.  Once you've completed your work, knit your Quarto document into an HTML document and save it within the folder you established in step 1.

6.  Please submit your assignment by uploading both the knitted HTML document and the QMD file to the specified course portal on Canvas prior to the designated due date and time

7.  Ensure your Quarto Document is saved with the following naming convention: "**LastName_FirstName_Week5.qmd**" (i.e. Doe_Jane_Week5.qmd). Students will lose 2 points for improper file naming.

8.  Please place your code for each task within the specified code section.

9.  Ensure that all non-code written responses are placed within the corresponding Task section where the question content is located.

10. You are allowed to seek assistance from ChatGPT exclusively for assistance in writing your code. However, please be cautious as ChatGPT may occasionally provide inaccurate information when it comes to scripting in specific programming languages.

11. Verbal responses must be articulated in your own words. You cannot use ChatGPT for generating or providing verbal responses. All verbal responses should originate from your own understanding and expression.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(rpart)
library(rsample)
library(caret)
library(mgcv)

knitr::opts_chunk$set(echo = TRUE)



```

## Week 5 Assignment

## Business Problem

For this week's homework, we'll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we'll be using is a randomly selected subset of the original dataset.

**Attributes:**

-   **Predictors**

    -   **fage**: father's age in years.

    -   **mage**: mother's age in years.

    -   **mature**: maturity status of mother.

    -   **weeks**: length of pregnancy in weeks.

    -   **premie**: whether the birth was classified as premature (premie) or full-term.

    -   **visits**: number of hospital visits during pregnancy.

    -   **marital**: whether mother is married or not married at birth.

    -   **gained**: weight gained by mother during pregnancy in pounds.

    -   **gender**: gender of the baby, female or male.

    -   **habit**: status of the mother as a nonsmoker or a smoker.

    -   **whitemom**: whether mother is white or not white.

**Outcome Variable:**

-   **weight**: weight of the baby at birth in pounds. (Regression problem)

#### Do not change anything in this r chunk. Just run the code chunk and move to the next one

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Run this code chunk without altering it
# clear the session
rm(list=ls())

# Data is stored in a csv file, the first row contains the variable names. 
# we call our data mydata
mydata<-read.csv ("Data_RLab5.csv", header=TRUE)

# remove lowbirthweight
mydata<-mydata%>%
  select(-lowbirthweight)




```

## Task 1: Data Preparation

::: {.callout-important appearance="simple"}
## Task 1

1.  **Data Structure Check**:

    -   Examine the variable descriptions and the overall structure of the dataset in **`mydata`**.

    -   Ensure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.

2.  **Handling Missing Values**:

    -   Identify and replace missing values in your dataset.

        -   For numeric variables, fill missing values with the median of that variable.

        -   For categorical variables, use the most frequent category (mode) to replace missing values.

3.  **Correlation Analysis and Visualization**:

    -   Determine the variable that has the highest correlation (in absolute value) with your chosen target variable.

    -   Create a scatter plot to visually represent the relationship between these two variables.

    -   Provide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.

    -   **Insert your written response in here:**
:::

## Your code for Task 1

```{r, echo=TRUE}
# Please provide your code for Task 1 in this code chunk

# Display the structure of the dataset
str(mydata)

# Convert character variables to factors
mydata$mature <- as.factor(mydata$mature)
mydata$premie <- as.factor(mydata$premie)
mydata$marital <- as.factor(mydata$marital)
mydata$gender <- as.factor(mydata$gender)
mydata$habit <- as.factor(mydata$habit)
mydata$whitemom <- as.factor(mydata$whitemom)

# Identify missing values
missing_values <- sapply(mydata, function(x) sum(is.na(x)))

# Display missing values
print(missing_values)

# Replace missing values with median for numeric variables and mode for factor variables

mydata$fage[is.na(mydata$fage)] <- median(mydata$fage, na.rm = TRUE)

mydata$mage[is.na(mydata$mage)] <- median(mydata$mage, na.rm = TRUE)

mode_mature <- levels(mydata$mature)[which.max(table(mydata$mature))]
mydata$mature[is.na(mydata$mature)] <- mode_mature

mydata$weeks[is.na(mydata$weeks)] <- median(mydata$weeks, na.rm = TRUE)

mode_premie <- levels(mydata$premie)[which.max(table(mydata$premie))]
mydata$premie[is.na(mydata$premie)] <- mode_premie

mydata$visits[is.na(mydata$visits)] <- median(mydata$visits, na.rm = TRUE)

mode_marital <- levels(mydata$marital)[which.max(table(mydata$marital))]
mydata$marital[is.na(mydata$marital)] <- mode_marital

mydata$gained[is.na(mydata$gained)] <- median(mydata$gained, na.rm = TRUE)

mydata$weight[is.na(mydata$weight)] <- median(mydata$weight, na.rm = TRUE)

mode_gender <- levels(mydata$gender)[which.max(table(mydata$gender))]
mydata$gender[is.na(mydata$gender)] <- mode_gender

mode_habit <- levels(mydata$habit)[which.max(table(mydata$habit))]
mydata$habit[is.na(mydata$habit)] <- mode_habit

mode_whitemom <- levels(mydata$whitemom)[which.max(table(mydata$whitemom))]
mydata$whitemom[is.na(mydata$whitemom)] <- mode_whitemom

# Group variables together for ease of coding
numeric_variables <- sapply(mydata, is.numeric)
categorical_variables <- sapply(mydata, is.factor)

# Verify that missing values are handled
missing_values_after <- sapply(mydata, function(x) sum(is.na(x)))
print(missing_values_after)

# Correlation analysis
correlation_matrix <- cor(mydata[, numeric_variables])
cor_target <- correlation_matrix[,'weight']

# Print correlation matrix
print("Correlation Matrix:")
print(correlation_matrix)

# from the correlation matrix, the strongest correlation to weight is weight, obviously. I have also created a second scatter plot that shows the 2nd strongest correlation between weight and weeks. This makes sense as babies that are born prematurely will weigh less than babies born on time, and as babies that are born closer to the expected due date will have their weights vary more. The correlation between weeks and weight is moderately positive. - EJD

# Identify the variable with the highest correlation
highest_correlation <- names(which.max(abs(cor_target)))

# Scatter plot
plot(mydata$weight, mydata[, highest_correlation], 
     xlab = 'Weight of the Baby at Birth (lbs)', 
     ylab = paste('Correlated Variable:', highest_correlation),
     main = 'Scatter Plot: Baby Weight vs. Highest Correlated Variable')
abline(lm(mydata[, highest_correlation] ~ mydata$weight), col = 'red')

# Create scatter plot
ggplot(mydata, aes(x = weeks, y = weight)) +
  geom_point() +
  labs(title = "Scatter Plot of Weeks vs. Weight",
       x = "Weeks",
       y = "Weight")
```

## Task 2: Data Splitting

------------------------------------------------------------------------

::: {.callout-important appearance="simple"}
## Task 2

-   Prior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you'll need to use the **`initial_split`** function from the **`rsample`** package in R to partition the data. Please ensure to use **`set.seed(123456)`** for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using `strata="weight"`.

-   Name your training set **`train_data`** and your test set **`test_data`**. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance.
:::

## Your code for Task 2

```{r, echo=TRUE}
# Please provide your code for Task 2 in this code chunk
# split the sample by using rsample package

# Split the data into a training set (70%) and a test set (30%)
set.seed(123456)

data_split <- initial_split(mydata, prop = 0.7, strata = "weight")

# Create training and test sets
train_data <- training(data_split)
test_data <- testing(data_split)
```

## Task 3:

::: {.callout-important appearance="simple"}
## Task 3

-   In this task, you will be using the **`train_data`** dataset to run a linear regression that takes `weight` as the dependent variable and all the other columns as the predictor.

    -   You will use the **`lm()`** function to estimate your linear model and name it as **`linearmodel`**.

    -   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`linearmodel`**.

    -   Store the resulting predictions in a new object called **`predicted_weights_ols`**.

    -   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted `weight` values with the actual `weight` values. Store the resulting value in an object called **`MSPE_linear`**.

-   **Need Written Response:** Print the value of **`MSPE_linear`** to the console using the **`print()`** function
:::

## Your code for Task 3

```{r, echo=TRUE}
# Please provide your code for Task 3  in this code chunk

# Run linear regression
linearmodel <- lm(weight ~ ., data = train_data)

# Predict weight in the test_data dataset
predicted_weights_ols <- predict(linearmodel, newdata = test_data)

# Calculate mean squared prediction error (MSPE)
MSPE_linear <- mean((predicted_weights_ols - test_data$weight)^2)

# Print the value of MSPE_linear to the console
print(MSPE_linear)

```

## Task 4:

::: {.callout-important appearance="simple"}
## Task 4

-   Use the `gam` function in the **`mgcv`** package to complete the same task. In other words, fit a Generalized additive model (GAM) on the `train_data` using the **`gam()`** function. Use the **`s()`** function for each **suitable** predictor. Save your R object as `gam_model.` If the `gam` output indicates that a variable should be added linearly to the model, then make the necessary changes in `gam_model` and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = "REML".
-   Print out smoothing parameter from `gam_model.`
-   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`gam_model`**. Store the resulting predictions in a new object called **`predicted_weights_gam`**.
-   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted 'weight' values with the actual `weight` values. Store the resulting value in an object called **`MSPE_gam`**.

Print the value of **`MSPE_gam`** to the console using the **`print()`** function.
:::

## Your code for Task 4

```{r, echo=TRUE}
# Please provide your code for Task 4 in this code chunk

# Fit a Generalized Additive Model (GAM) with reduced degrees of freedom
gam_model <- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + s(gained) + marital + habit + whitemom + premie + gender, data = train_data, method = "REML")

# Trim the GAM model to smooth the correct degrees of freedom

gam_model_rev <- gam(weight ~ fage + mage + s(weeks) + s(visits) + gained + marital + habit + whitemom + premie + gender, data = train_data, method = "REML")


# Print smoothing parameters
summary(gam_model)$s.table

# Predict weight in the test_data dataset using gam_model
predicted_weights_gam <- predict(gam_model, newdata = test_data)

# Calculate mean squared prediction error (MSPE) for the GAM model
MSPE_gam <- mean((predicted_weights_gam - test_data$weight)^2)

# Print the value of MSPE_gam to the console
print(MSPE_gam)



```

------------------------------------------------------------------------

## TASK 5:

::: {.callout-important appearance="simple"}
## Task 5

-   Evaluate the effectiveness of the linear regression model (**`linearmodel`**) and the generalized additive model (**`gam_model`**) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values **`MSPE_linear`** and **`MSPE_gam`**, which were derived in previous tasks, to assess which model more accurately predicts the 'weight' variable in the **`test_data`** dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.
-   **Insert your written response in here:**
:::

## Your code for Task 5

```{r, echo=TRUE}
# Please provide your code for Task 5 in this code chunk

# Compare MSPE for linear regression and GAM models
cat("Mean Squared Prediction Error (MSPE) for Linear Regression Model:", round(MSPE_linear, 4), "\n")
cat("Mean Squared Prediction Error (MSPE) for Generalized Additive Model (GAM):", round(MSPE_gam, 4), "\n")

# Evaluate model performance
if (MSPE_linear < MSPE_gam) {
  cat("Linear Regression Model has superior predictive performance for 'weight'.\n")
} else if (MSPE_gam < MSPE_linear) {
  cat("Generalized Additive Model (GAM) has superior predictive performance for 'weight'.\n")
} else {
  cat("Both models have similar predictive performance for 'weight'.\n")
}

# The GAM model performs better at predicting the target variable due to it having a lower MSPE as shown in the code block. - EJD
```
